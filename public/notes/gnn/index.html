<!DOCTYPE html>
<html lang="en-us">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta http-equiv="X-UA-Compatible" content="ie=edge">
	<meta name="theme-color" content="#494f5c">
	<meta name="msapplication-TileColor" content="#494f5c">
<meta itemprop="name" content="An intro to Graph Machine Learning">
<meta itemprop="description" content="Graph data is quite abundant around us. Almost all data that we can think of can be represented as a graph in some way or the other. Apart from the obvious applications of graph research in GPS and the analysis of social networks, we can also model a lot of other data in graphs. For example, images can be thought of as just nodes with RGB features connected as a grid."><meta itemprop="datePublished" content="2022-10-18T14:56:19+05:30" />
<meta itemprop="dateModified" content="2022-10-18T14:56:19+05:30" />
<meta itemprop="wordCount" content="584">
<meta itemprop="keywords" content="graphs," /><meta property="og:title" content="An intro to Graph Machine Learning" />
<meta property="og:description" content="Graph data is quite abundant around us. Almost all data that we can think of can be represented as a graph in some way or the other. Apart from the obvious applications of graph research in GPS and the analysis of social networks, we can also model a lot of other data in graphs. For example, images can be thought of as just nodes with RGB features connected as a grid." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://sravjti.in/ML-study-group/notes/gnn/" /><meta property="article:section" content="notes" />
<meta property="article:published_time" content="2022-10-18T14:56:19+05:30" />
<meta property="article:modified_time" content="2022-10-18T14:56:19+05:30" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="An intro to Graph Machine Learning"/>
<meta name="twitter:description" content="Graph data is quite abundant around us. Almost all data that we can think of can be represented as a graph in some way or the other. Apart from the obvious applications of graph research in GPS and the analysis of social networks, we can also model a lot of other data in graphs. For example, images can be thought of as just nodes with RGB features connected as a grid."/>

	<link rel="apple-touch-icon" sizes="180x180" href="/ML-study-group/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/ML-study-group/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/ML-study-group/favicon-16x16.png">
	<link rel="manifest" href="/ML-study-group/site.webmanifest">
	<link rel="mask-icon" href="/ML-study-group/safari-pinned-tab.svg" color="">
	<link rel="shortcut icon" href="/ML-study-group/favicon.ico">

	<title>An intro to Graph Machine Learning</title>
	<link rel="stylesheet" href="https://sravjti.in/ML-study-group/css/style.min.1880a53e93805e9dd23983de006b12e4c911609c4c537a264e14d0b330fd6888.css" integrity="sha256-GIClPpOAXp3SOYPeAGsS5MkRYJxMU3omThTQszD9aIg=" crossorigin="anonymous">
	
</head>

<body id="page">
	
	<header id="site-header" class="animated slideInUp">
		<div class="hdr-wrapper section-inner">
			<div class="hdr-left">
				<div class="site-branding">
					<a href="https://sravjti.in/ML-study-group/">ML Study Group</a>
				</div>
				<nav class="site-nav hide-in-mobile">
					
				<a href="https://sravjti.in/ML-study-group/notes/">Notes</a>

				</nav>
			</div>
			<div class="hdr-right hdr-icons">
				<span class="hdr-social hide-in-mobile"><a href="mailto:sra@vjti.ac.in" target="_blank" rel="noopener me" title="Email"><svg xmlns="http://www.w3.org/2000/svg" class="feather" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"></path><polyline points="22,6 12,13 2,6"></polyline></svg></a><a href="https://github.com/SRA-VJTI" target="_blank" rel="noopener me" title="Github"><svg xmlns="http://www.w3.org/2000/svg" class="feather" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg></a></span><button id="menu-btn" class="hdr-btn" title="Menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button>
			</div>
		</div>
	</header>
	<div id="mobile-menu" class="animated fast">
		<ul>
			<li><a href="https://sravjti.in/ML-study-group/notes/">Notes</a></li>
		</ul>
	</div>


	<main class="site-main section-inner thin animated fadeIn faster">
		<h1>An intro to Graph Machine Learning</h1>
		<div class="content">
			<p>Graph data is quite abundant around us. Almost all data that we can think of can be represented as a graph in some way or the other. Apart from the obvious applications of graph research in GPS and the analysis of social networks, we can also model a lot of other data in graphs. For example, images can be thought of as just nodes with RGB features connected as a grid. NLP research also makes a lot of graph data for example parse trees etc. Graph ML, as a whole is applied in a large variety of domains like:</p>
<ul>
<li>Physics: Detecting and plotting the course of particles in a collider experiment.</li>
<li>Biology: Using gene analysis and GNNs to predict the possibility of a patient responding to a certain kind of statement.</li>
<li>Chemistry: Used by pharmacists to model drug-drug, drug-protein and protein-protein interactions to understand how effective or detrimental a substance can be to one&rsquo;s body.</li>
</ul>
<h1 id="graph-embedding-methods">Graph Embedding Methods<a href="#graph-embedding-methods" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<p>Graph Embedding Methods deal with representing the nodes of a graph as vectors in multidimensional vector space. This is called a <strong>latent</strong> representation, because it itself may not hold a lot of obvious meaning, but it encodes the relationships in the graph well. The given outputs are in continuous vector space can be easily explored and exploited using existing statistical methods.</p>
<h2 id="dealing-with-sparsity-while-creating-graph-embeddings">Dealing with Sparsity while creating Graph Embeddings<a href="#dealing-with-sparsity-while-creating-graph-embeddings" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2>
<p>A graph can either be considered as dense (a lot of edges as compared to the nodes) or sparse (a lot less edges as compared to nodes). Analyzing sparse graphs is easier when we are trying to apply combinatorial techniques. However, it doesn&rsquo;t work well when we try to use statistical techniques on sparse graphs. This problem will have to be dealt with if we are trying to learn an embedding for a graph.</p>
<h2 id="learning-social-representations">Learning Social representations<a href="#learning-social-representations" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2>
<p>Graph Embeddings seek to learn latent representations of social interactions in the graph. For this they must have the following qualities.</p>
<ol>
<li>Adaptability: This relates to the ease of training a latent representation. Newer nodes or edges should not trigger a complete retraining of the embedding.</li>
<li>Community Aware: The distance between nodes though the latent dimensions should represent a metric for evaluating social similarity between them. This allows for easier generalisation of the networks and better results when statistical methods are applied on the resultant representations.</li>
<li>Low-dimensional: The lower the number of dimensions in the representation, the easier it will be to make inferences and converge on a final representation.</li>
<li>Continuous: The resultant representation must be over continuous space thus allowing for smoother decision boundaries in downstream tasks.</li>
</ol>
<h2 id="random-walks">Random Walks<a href="#random-walks" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2>
<p>For creating embeddings we need to transform the graph data into something that can effectively stream the structure of the graph (and hence it&rsquo;s short-term and long-term complexities). Short random walks are perfect for this. Shorter term complexities are captured well by the actual structure and orderings of the nodes in the walk. Longer term complexities are captured through the probability distribution from which the initial node is sampled.</p>
<p>Methods that use <strong>short random walks</strong> have 2 particular advantages:</p>
<ul>
<li>These are trivially easy to paralellize. Several parallel computational resources (like threads, processes or machines) can be set up to explore different versions of the graph parallely.</li>
<li>Since the walks are short, at a time only a small subset of nodes will be updated at the same time. This makes it easy to accomodate small changes to an existing embedding without the need for global recomputation.</li>
</ul>
<p>Citation: <a href="https://arxiv.org/abs/1403.6652">DeepWalk: Online Learning of Social Representations</a></p>

		</div>
	</main>

	<footer id="site-footer" class="section-inner thin animated fadeIn faster">
		<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script>
		<p>&copy; 2022 <a href="https://sravjti.in/ML-study-group/">SRA VJTI</a></p>
		<p>
			Made with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> &#183; Theme <a href="https://github.com/Track3/hermit" target="_blank" rel="noopener">Hermit</a>
		</p>
	</footer>



	<script src="https://sravjti.in/ML-study-group/js/bundle.min.580988ed2982bcbb74a1773c7abea97b43e4c43b9324e10cda0813ec6ec4bb67.js" integrity="sha256-WAmI7SmCvLt0oXc8er6pe0PkxDuTJOEM2ggT7G7Eu2c=" crossorigin="anonymous"></script>
	

</body>

</html>
